{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2088f3de-95a7-4f75-a406-79cbb2c79f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:51:36.603739Z",
     "iopub.status.busy": "2025-07-26T16:51:36.603433Z",
     "iopub.status.idle": "2025-07-26T16:51:48.820715Z",
     "shell.execute_reply": "2025-07-26T16:51:48.819983Z",
     "shell.execute_reply.started": "2025-07-26T16:51:36.603719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 16:51:36.823102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 1.- Preparación del entorno\n",
    "# Importa TensorFlow, necesario para construir y\n",
    "# entrenar el modelo.\n",
    "import tensorflow as tf\n",
    "\n",
    "#para construir y entrenar el modelo.\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# para visualizar resultados.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# para manejar arrays.\n",
    "import numpy as np\n",
    "\n",
    "# para interactuar con el sistema de archivos.\n",
    "import os\n",
    "\n",
    "# para dividir los datos en entrenamiento y prueba.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# para cargar y procesar imágenes.\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b54897-db29-4bd1-8e88-3ad18a3276a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:51:48.822291Z",
     "iopub.status.busy": "2025-07-26T16:51:48.821762Z",
     "iopub.status.idle": "2025-07-26T16:57:29.401742Z",
     "shell.execute_reply": "2025-07-26T16:57:29.400776Z",
     "shell.execute_reply.started": "2025-07-26T16:51:48.822258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apparel-images-dataset\n",
      "Directorio actual: /home/784415da-63f5-445e-ab26-1e7f31e326b5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 2.- Primero, descargamos y descomprimimos el dataset desde Kaggle. \n",
    "# Luego, organizamos las imágenes en carpetas por clase \n",
    "# (por ejemplo: Shirt, Dress, Jeans, etc.).\n",
    "\n",
    "# Define la ruta del dataset.\n",
    "data_dir = './apparel-images-dataset'\n",
    "# Verificamos que la ruta exista\n",
    "print(data_dir)\n",
    "current_dir = os.getcwd()\n",
    "print(\"Directorio actual:\", current_dir)\n",
    "print(os.path.exists(data_dir))  # Should return True if the path is valid\n",
    "\n",
    "# definimos las dimensiones con que se van a\n",
    "# normalizar las imágenes, en pixeles.\n",
    "# img_height, img_width = 128, 128\n",
    "img_height, img_width = 128, 128\n",
    "# definimos una función para cargar las imágenes.\n",
    "def load_images(data_dir):\n",
    "    # Inicializa dos listas vacías:\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = os.listdir(data_dir)\n",
    "    # Recorre las carpetas por clase (por ejemplo: Shirt, Dress).\n",
    "    # Carga cada imagen, la convierte a RGB, \n",
    "    # la redimensiona a 128x128 y \n",
    "    # la guarda junto con su etiqueta.\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB').resize((img_width, img_height))\n",
    "                # Convierte la imagen a un array NumPy y \n",
    "                # lo agrega a images.\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                continue\n",
    "    # regresa un arreglo con imágenes y etiquetas\n",
    "    return np.array(images), np.array(labels)\n",
    "# cargamos las imágenes y etiquetas utilizando la \n",
    "# función recien definida.\n",
    "# Carga todas las imágenes y etiquetas en memoria.\n",
    "images, labels = load_images(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7e415e-4062-43af-a60a-bef5cd2ef834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:57:29.502720Z",
     "iopub.status.busy": "2025-07-26T16:57:29.502450Z",
     "iopub.status.idle": "2025-07-26T16:58:21.223964Z",
     "shell.execute_reply": "2025-07-26T16:58:21.222904Z",
     "shell.execute_reply.started": "2025-07-26T16:57:29.502702Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. División en entrenamiento y prueba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# conviertimos las etiquetas de texto en números enteros.\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "# Separaramos el 20% de los datos para prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels_encoded, test_size=0.2, random_state=42\n",
    "    # El parámetro random_state en train_test_split \n",
    "    # controla la aleatoriedad de la división de datos. \n",
    "    # Usar un valor fijo como 42 garantiza que:\n",
    "    # La división entre entrenamiento y prueba siempre \n",
    "    # sea la misma cada vez que se ejecute el código.\n",
    "    # Esto permite reproducibilidad.\n",
    "    )\n",
    "\n",
    "# escalamos los valores de píxeles de 0–255 a \n",
    "# valores entre 0–1,lo que ayuda al modelo a\n",
    "# entrenar más eficientemente.\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029c3051-8885-4583-a8b0-cddbb8792e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:58:21.321845Z",
     "iopub.status.busy": "2025-07-26T16:58:21.321535Z",
     "iopub.status.idle": "2025-07-26T16:58:22.608154Z",
     "shell.execute_reply": "2025-07-26T16:58:22.607006Z",
     "shell.execute_reply.started": "2025-07-26T16:58:21.321819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 16:58:21.517376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-26 16:58:21.525177: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 126, 126, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 61, 61, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,308,632\n",
      "Trainable params: 3,308,184\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4. Construcción del modelo\n",
    "# from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(np.unique(labels_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compilación con optimizador ajustado\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Define a sequential CNN model for image classification\n",
    "#model = models.Sequential([\n",
    "    # First convolutional layer with 16 filters of size 3x3, ReLU activation\n",
    "    # Input shape specifies the dimensions of our images (height, width, channels)\n",
    "    #layers.Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    # Max pooling layer to reduce spatial dimensions by half (2x2 pooling)\n",
    "    #layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Second convolutional layer with 32 filters of size 3x3, ReLU activation\n",
    "    #layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Another max pooling layer to further reduce dimensions\n",
    "    #layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the 2D feature maps to 1D for the dense layers\n",
    "    #layers.Flatten(),\n",
    "    # Dropout layer with 30% rate to prevent overfitting during training\n",
    "    #layers.Dropout(0.3),  # Reduce overfitting sin añadir parámetros\n",
    "    # Dense hidden layer with 64 neurons and ReLU activation\n",
    "    #layers.Dense(64, activation='relu'),\n",
    "    # Output layer with neurons equal to number of classes, softmax for probability distribution\n",
    "    #layers.Dense(len(le.classes_), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f757487d-5710-48ac-9b55-fee589a8e73c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:58:22.712600Z",
     "iopub.status.busy": "2025-07-26T16:58:22.712303Z",
     "iopub.status.idle": "2025-07-26T16:58:22.716864Z",
     "shell.execute_reply": "2025-07-26T16:58:22.715460Z",
     "shell.execute_reply.started": "2025-07-26T16:58:22.712573Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Entrenamiento del modelo\n",
    "# history = model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b744ec-bddf-4405-90ec-9632a7209e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T16:58:22.812702Z",
     "iopub.status.busy": "2025-07-26T16:58:22.812501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Entrenamiento del modelo\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694d03c-f003-45c8-8726-338943c849b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluación del modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en el conjunto de prueba: {test_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f36fd-6c41-481b-8e98-e0613c93f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualización del rendimiento\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.legend()\n",
    "plt.title('Precisión del modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f407d10-2ebd-44b8-b00d-ed7088a83421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
