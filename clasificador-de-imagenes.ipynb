{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2088f3de-95a7-4f75-a406-79cbb2c79f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:09:35.164046Z",
     "iopub.status.busy": "2025-07-26T23:09:35.163695Z",
     "iopub.status.idle": "2025-07-26T23:09:40.837176Z",
     "shell.execute_reply": "2025-07-26T23:09:40.836479Z",
     "shell.execute_reply.started": "2025-07-26T23:09:35.164028Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 23:09:35.259033: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 1.- Preparación del entorno\n",
    "# Importa TensorFlow, necesario para construir y\n",
    "# entrenar el modelo.\n",
    "import tensorflow as tf\n",
    "\n",
    "#para construir y entrenar el modelo.\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# para visualizar resultados.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# para manejar arrays.\n",
    "import numpy as np\n",
    "\n",
    "# para interactuar con el sistema de archivos.\n",
    "import os\n",
    "\n",
    "# para dividir los datos en entrenamiento y prueba.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# para cargar y procesar imágenes.\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b54897-db29-4bd1-8e88-3ad18a3276a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:09:40.838989Z",
     "iopub.status.busy": "2025-07-26T23:09:40.838438Z",
     "iopub.status.idle": "2025-07-26T23:11:07.552542Z",
     "shell.execute_reply": "2025-07-26T23:11:07.551850Z",
     "shell.execute_reply.started": "2025-07-26T23:09:40.838961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apparel-images-dataset\n",
      "Directorio actual: /home/784415da-63f5-445e-ab26-1e7f31e326b5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 2.- Primero, descargamos y descomprimimos el dataset desde Kaggle. \n",
    "# Luego, organizamos las imágenes en carpetas por clase \n",
    "# (por ejemplo: Shirt, Dress, Jeans, etc.).\n",
    "\n",
    "# Define la ruta del dataset.\n",
    "data_dir = './apparel-images-dataset'\n",
    "# Verificamos que la ruta exista\n",
    "print(data_dir)\n",
    "current_dir = os.getcwd()\n",
    "print(\"Directorio actual:\", current_dir)\n",
    "print(os.path.exists(data_dir))  # Should return True if the path is valid\n",
    "\n",
    "# definimos las dimensiones con que se van a\n",
    "# normalizar las imágenes, en pixeles.\n",
    "# img_height, img_width = 128, 128\n",
    "img_height, img_width = 96, 96\n",
    "# definimos una función para cargar las imágenes.\n",
    "def load_images(data_dir):\n",
    "    # Inicializa dos listas vacías:\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = os.listdir(data_dir)\n",
    "    # Recorre las carpetas por clase (por ejemplo: Shirt, Dress).\n",
    "    # Carga cada imagen, la convierte a RGB, \n",
    "    # la redimensiona a 128x128 y \n",
    "    # la guarda junto con su etiqueta.\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB').resize((img_width, img_height))\n",
    "                # Convierte la imagen a un array NumPy y \n",
    "                # lo agrega a images.\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                continue\n",
    "    # regresa un arreglo con imágenes y etiquetas\n",
    "    return np.array(images), np.array(labels)\n",
    "# cargamos las imágenes y etiquetas utilizando la \n",
    "# función recien definida.\n",
    "# Carga todas las imágenes y etiquetas en memoria.\n",
    "images, labels = load_images(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7e415e-4062-43af-a60a-bef5cd2ef834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:11:07.568365Z",
     "iopub.status.busy": "2025-07-26T23:11:07.568125Z",
     "iopub.status.idle": "2025-07-26T23:11:09.832374Z",
     "shell.execute_reply": "2025-07-26T23:11:09.831668Z",
     "shell.execute_reply.started": "2025-07-26T23:11:07.568348Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. División en entrenamiento y prueba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# conviertimos las etiquetas de texto en números enteros.\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "# Separaramos el 20% de los datos para prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels_encoded, test_size=0.2, random_state=42\n",
    "    # El parámetro random_state en train_test_split \n",
    "    # controla la aleatoriedad de la división de datos. \n",
    "    # Usar un valor fijo como 42 garantiza que:\n",
    "    # La división entre entrenamiento y prueba siempre \n",
    "    # sea la misma cada vez que se ejecute el código.\n",
    "    # Esto permite reproducibilidad.\n",
    "    )\n",
    "\n",
    "# escalamos los valores de píxeles de 0–255 a \n",
    "# valores entre 0–1,lo que ayuda al modelo a\n",
    "# entrenar más eficientemente.\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029c3051-8885-4583-a8b0-cddbb8792e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:11:09.845948Z",
     "iopub.status.busy": "2025-07-26T23:11:09.845710Z",
     "iopub.status.idle": "2025-07-26T23:11:10.107868Z",
     "shell.execute_reply": "2025-07-26T23:11:10.107241Z",
     "shell.execute_reply.started": "2025-07-26T23:11:09.845932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 94, 94, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 47, 47, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 47, 47, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 45, 45, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 20, 20, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1638528   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,735,768\n",
      "Trainable params: 1,735,320\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 23:11:09.877146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-26 23:11:09.880575: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# 4. Construcción del modelo\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
    "]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(np.unique(labels_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compilación con optimizador ajustado\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Define a sequential CNN model for image classification\n",
    "#model = models.Sequential([\n",
    "    # First convolutional layer with 16 filters of size 3x3, ReLU activation\n",
    "    # Input shape specifies the dimensions of our images (height, width, channels)\n",
    "    #layers.Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    # Max pooling layer to reduce spatial dimensions by half (2x2 pooling)\n",
    "    #layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Second convolutional layer with 32 filters of size 3x3, ReLU activation\n",
    "    #layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Another max pooling layer to further reduce dimensions\n",
    "    #layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the 2D feature maps to 1D for the dense layers\n",
    "    #layers.Flatten(),\n",
    "    # Dropout layer with 30% rate to prevent overfitting during training\n",
    "    #layers.Dropout(0.3),  # Reduce overfitting sin añadir parámetros\n",
    "    # Dense hidden layer with 64 neurons and ReLU activation\n",
    "    #layers.Dense(64, activation='relu'),\n",
    "    # Output layer with neurons equal to number of classes, softmax for probability distribution\n",
    "    #layers.Dense(len(le.classes_), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f757487d-5710-48ac-9b55-fee589a8e73c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:11:10.124656Z",
     "iopub.status.busy": "2025-07-26T23:11:10.124316Z",
     "iopub.status.idle": "2025-07-26T23:11:10.127581Z",
     "shell.execute_reply": "2025-07-26T23:11:10.126853Z",
     "shell.execute_reply.started": "2025-07-26T23:11:10.124637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Entrenamiento del modelo\n",
    "# history = model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b744ec-bddf-4405-90ec-9632a7209e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T23:11:10.142121Z",
     "iopub.status.busy": "2025-07-26T23:11:10.141843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "228/228 [==============================] - 112s 486ms/step - loss: 2.4235 - accuracy: 0.3214 - val_loss: 10.2081 - val_accuracy: 0.0582 - lr: 5.0000e-04\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 110s 482ms/step - loss: 1.7280 - accuracy: 0.4909 - val_loss: 2.8415 - val_accuracy: 0.3622 - lr: 5.0000e-04\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 154s 675ms/step - loss: 1.3825 - accuracy: 0.5957 - val_loss: 1.0790 - val_accuracy: 0.7184 - lr: 5.0000e-04\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 216s 942ms/step - loss: 1.1772 - accuracy: 0.6426 - val_loss: 0.7691 - val_accuracy: 0.7788 - lr: 5.0000e-04\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 115s 502ms/step - loss: 1.0239 - accuracy: 0.6841 - val_loss: 0.7611 - val_accuracy: 0.7953 - lr: 5.0000e-04\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 114s 502ms/step - loss: 0.9622 - accuracy: 0.7101 - val_loss: 0.7662 - val_accuracy: 0.7881 - lr: 5.0000e-04\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 110s 485ms/step - loss: 0.8530 - accuracy: 0.7337 - val_loss: 0.7263 - val_accuracy: 0.7788 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 107s 471ms/step - loss: 0.7869 - accuracy: 0.7550 - val_loss: 0.6971 - val_accuracy: 0.8074 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 107s 472ms/step - loss: 0.7350 - accuracy: 0.7715 - val_loss: 0.8253 - val_accuracy: 0.7958 - lr: 5.0000e-04\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 431s 2s/step - loss: 0.6854 - accuracy: 0.7858 - val_loss: 0.5614 - val_accuracy: 0.8480 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      " 54/228 [======>.......................] - ETA: 13:48 - loss: 0.6421 - accuracy: 0.7853"
     ]
    }
   ],
   "source": [
    "# 5. Entrenamiento del modelo\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    # callbacks=[early_stop]\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694d03c-f003-45c8-8726-338943c849b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluación del modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en el conjunto de prueba: {test_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f36fd-6c41-481b-8e98-e0613c93f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualización del rendimiento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f407d10-2ebd-44b8-b00d-ed7088a83421",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matriz de confusión\n",
    "Para evaluar el rendimiento por clase:\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740de1fb-b207-4460-a516-39dea9145ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
